{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678bcb2-f3d3-4a18-a61b-4469169d23cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "#load telematics data\n",
    "df = pd.read_csv(\"G9WT3MTW2E7Z.csv\")\n",
    "print(tabulate(df.head(), headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9d58c-6563-447f-82f2-28bf6ebb29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#droping columns\n",
    "columns_to_drop = [\"telematics_id\", \"h2gen_id\", \"fuel_lifetime\", \"fuel_telematics\", \"engine_speed\", \"runtime\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "#converting timestamp to datetime\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "#handling missing values (-1 to NaN)\n",
    "df[\"odometer\"] = df[\"odometer\"].replace(-1, np.nan)\n",
    "\n",
    "#droping rows with missing speed, timestamp, latitude, longitude\n",
    "df = df.dropna(subset=[\"speed\", \"timestamp\", \"latitude\", \"longitude\"])\n",
    "print(f\"After dropping NaN speeds/locations: {len(df)} rows\")\n",
    "print(tabulate(df.head(), headers=\"keys\", tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f2d2a-9c0b-4bd1-9768-f1dfed4b3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling duplicate timestamps\n",
    "df_avg = df.groupby(\"timestamp\").agg({\n",
    "    \"speed\": \"mean\",\n",
    "    \"latitude\": \"first\",\n",
    "    \"longitude\": \"first\",\n",
    "    \"odometer\": \"first\"\n",
    "}).reset_index()\n",
    "print(f\"After averaging same timestamps: {len(df_avg)} rows\")\n",
    "print(tabulate(df_avg.head(), headers=\"keys\", tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10315e-9829-4048-bfbc-06deea318fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#segmenting into driving sessions (time gap > 5 min)\n",
    "df_avg[\"time_diff\"] = df_avg[\"timestamp\"].diff().dt.total_seconds().fillna(0)\n",
    "df_avg[\"session\"] = (df_avg[\"time_diff\"] > 300).cumsum()\n",
    "print(f\"Number of sessions: {df_avg['session'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f6548-3214-4794-8c9d-176a2745418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd72ff5-f8e8-4c10-93a2-694789d477d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine\n",
    "\n",
    "#calculating features per session\n",
    "features = []\n",
    "for session_id, session_df in df_avg.groupby(\"session\"):\n",
    "\n",
    "    #avg speed (moving average)\n",
    "    moving_speeds = session_df[\"speed\"][session_df[\"speed\"] > 0]\n",
    "    if len(moving_speeds) > 0:\n",
    "        avg_speed = moving_speeds.mean()\n",
    "    else:\n",
    "        avg_speed = 0\n",
    "\n",
    "    #max speed\n",
    "    max_speed = session_df[\"speed\"].max()\n",
    "\n",
    "    #avg acceleration\n",
    "    speeds = session_df[\"speed\"].values\n",
    "    times = (session_df[\"timestamp\"] - session_df[\"timestamp\"].iloc[0]).dt.total_seconds().values\n",
    "    accel = []\n",
    "    for i in range(1, len(speeds)):\n",
    "        delta_speed = speeds[i] - speeds[i-1]\n",
    "        delta_time = times[i] - times[i-1]\n",
    "        if delta_time > 0:\n",
    "            accel.append(delta_speed / delta_time)\n",
    "    avg_accel = np.mean(np.abs(accel)) if accel else 0\n",
    "\n",
    "    #distance (using odometer or Haversine)\n",
    "    if session_df[\"odometer\"].isnull().sum() == 0:\n",
    "        distance = session_df[\"odometer\"].iloc[-1] - session_df[\"odometer\"].iloc[0]\n",
    "    else:\n",
    "        distance = 0\n",
    "        for i in range(1, len(session_df)):\n",
    "            coord1 = (session_df[\"latitude\"].iloc[i-1], session_df[\"longitude\"].iloc[i-1])\n",
    "            coord2 = (session_df[\"latitude\"].iloc[i], session_df[\"longitude\"].iloc[i])\n",
    "            distance += haversine(coord1, coord2)\n",
    "\n",
    "    #idle fraction\n",
    "    idle_fraction = (session_df[\"speed\"] == 0).mean()\n",
    "\n",
    "    features.append([avg_speed, max_speed, avg_accel, distance, idle_fraction])\n",
    "    print(f\"Session {session_id}: Avg_Speed={avg_speed:.2f}, Max_Speed={max_speed:.2f}, Avg_Accel={avg_accel:.2f}, Distance={distance:.2f}, Idle_Fraction={idle_fraction:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a269f8-c121-4245-b0e2-253e229fea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating features dataframe\n",
    "features_df = pd.DataFrame(features, columns=[\"Avg_Speed\", \"Max_Speed\", \"Avg_Accel\", \"Distance\", \"Idle_Fraction\"])\n",
    "print(f\"Features DataFrame: {len(features_df)} rows\")\n",
    "print(tabulate(features_df.head(), headers=\"keys\", tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd5a7c-1c4e-4867-9d51-37ad34e556f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#standardizing features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782b428-59d2-43b4-b885-06aaee046e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#computing inertia and silhouette scores for k=2 to 10\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "\n",
    "k_range = range(2, 11)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=101)\n",
    "    kmeans.fit(scaled_features)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(scaled_features, kmeans.labels_))\n",
    "\n",
    "#plot inertia - elbow method\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_range, inertia, marker=\"o\", color=\"blue\")\n",
    "plt.title(\"Elbow Method\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da68b1-f629-40d3-88af-fc053cc9573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot silhouette scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_range, silhouette_scores, marker=\"s\", color=\"red\")\n",
    "plt.title(\"Silhouette Score vs. Number of Clusters\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe99ca-928c-4c7e-b297-557c0e0ad1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying K-Means clustering (k=3)\n",
    "kmeans = KMeans(n_clusters=3, random_state=101)\n",
    "features_df[\"Cluster\"] = kmeans.fit_predict(scaled_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64426cd-191e-4e64-a746-f3151a008598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping clusters to desired labels\n",
    "cluster_map = {\n",
    "    0: \"Fast-paced and Long-Haul Driving\",\n",
    "    1: \"Slow and Idle-Prone\",\n",
    "    2: \"Moderate and Mixed-Pattern\"\n",
    "}\n",
    "\n",
    "features_df[\"Cluster_Label\"] = features_df[\"Cluster\"].map(cluster_map)\n",
    "\n",
    "#displaying results\n",
    "print(\"\\nFinal Clusters:\")\n",
    "print(tabulate(features_df.head(), headers=\"keys\", tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c28dd3-1e56-4138-93b6-85aaa88260ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "#PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "pca_components = pca.fit_transform(scaled_features)\n",
    "\n",
    "features_df[\"PCA1\"] = pca_components[:, 0]\n",
    "features_df[\"PCA2\"] = pca_components[:, 1]\n",
    "\n",
    "#scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=features_df, x=\"PCA1\", y=\"PCA2\", hue=\"Cluster_Label\", palette=\"viridis\", s=100)\n",
    "plt.title(\"Clusters and Centroids after PCA\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend(title=\"Cluster\", loc=\"upper center\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
